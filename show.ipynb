{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient cross scale fusion network SCW-YOLO for object detection in remote sensing imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABSTRACT\n",
    "Traditional object detection algorithms often struggle to detect small objects in remote sensing images because of their small size and complex backgrounds. To address this, We propose a high performance remote sensing image object detection model SCW-YOLO based on the YOLOv8 model. Firstly, the model incorporated an Efficient Cross Scale Feature Pyramid Network (ECFPN) to enabled richer feature fusion without increasing computational costs caused by continuous downsampling by adding a new feature layer to the shallow network and directly outputting the backbone network features to the detection head. Additionally, a coordinate attention mechanism was employed to refine the backbone network by locally enhancing the features and reducing interference from redundant information. Finally, to further improve bounding box loss fitting and accelerate network convergence, a dynamic non-monotonic Wise-IoU (WIOU) loss function was introduced to replace the loss function of baseline. The experimental results indicated that SCW-YOLO outperformed most state-of-the-art (SOTA) models in parameter efficiency and small-object detection accuracy, confirming its robustness in detecting small targets in remote sensing images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Download [YOLOv8](https://github.com/ultralytics/ultralytics/tree/v8.1.6) code. Pip install ultralytics and dependencies and check software and hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics\n",
    "import ultralytics\n",
    "\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECFPN\n",
    "The neck structure is displayed as follows.\n",
    "\n",
    "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n",
    "  - [[-1, 4], 1, Concat, [1]]  \n",
    "  - [-1, 3, C2f, [256]] \n",
    "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n",
    "  - [[-1, 2], 1, Concat, [1]]  \n",
    "  - [-1, 3, C2f, [128]]  \n",
    "  - [-1, 1, Conv, [128, 3, 2]]\n",
    "  - [[-1, 10, 4], 1, Concat, [1]]  \n",
    "  - [-1, 3, C2f, [256]]  \n",
    "  - [-1, 1, Conv, [256, 3, 2]]\n",
    "  - [[-1, 7], 1, Concat, [1]]  \n",
    "  - [-1, 3, C2f, [512]]  \n",
    "  - [[13, 16, 19], 1, Detect, [nc]]  # Detect(P2, P3, P4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backbone Enhance\n",
    "The backbone structure is displayed as follows.\n",
    "\n",
    "backbone:\n",
    "  - [-1, 1, Conv, [64, 3, 2]]  \n",
    "  - [-1, 1, Conv, [128, 3, 2]]  \n",
    "  - [-1, 3, C2f, [128, True]]\n",
    "  - [-1, 1, Conv, [256, 3, 2]]  \n",
    "  - [-1, 1, C2f_CooreA, [256, True]]\n",
    "  - [-1, 1, Conv, [512, 3, 2]]  \n",
    "  - [-1, 1, C2f_CooreA, [512, True]]\n",
    "  - [-1, 1, SPPF, [512, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the contents of the block.cy file in the modules file were added to the corresponding block.py file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIOU\n",
    "Fristly, Replace the original bbox_iou function with the bbox_iou function provided by metrics.py in the module file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondly, modify BboxLoss class in the loss.py file\n",
    "\n",
    "# original\n",
    "# iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, CIoU=True)\n",
    "# loss_iou = ((1.0 - iou) * weight).sum() / target_scores_sum\n",
    "\n",
    "# replace to\n",
    "iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, WIoU=True, scale=True)\n",
    "if type(iou) is tuple:\n",
    "    if len(iou) == 2:\n",
    "        loss_iou = ((1.0 - iou[0]) * iou[1].detach() * weight).sum() / target_scores_sum\n",
    "    else:\n",
    "        loss_iou = (iou[0] * iou[1] * weight).sum() / target_scores_sum\n",
    "else:\n",
    "    loss_iou = ((1.0 - iou) * weight).sum() / target_scores_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, modify bbox_iou in the tal.py file\n",
    "# overlaps[mask_gt] = bbox_iou(gt_boxes, pd_boxes, xywh=False, CIoU=True).squeeze(-1).clamp_(0)\n",
    "\n",
    "# repalce to \n",
    "overlaps[mask_gt] = bbox_iou(gt_boxes, pd_boxes, xywh=False).squeeze(-1).clamp_(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Download the datasets([DOTA](https://captain-whu.github.io/DOTA/dataset.html)) and place it in a location you know. Firstly, it is necessary to preprocess the DOTA dataset and select five types of research objects: small cars, large cars, airplanes, ships, and oil storage tanks, with target sizes less than 0.5% of the entire image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select five types of research objects\n",
    "import os\n",
    "\n",
    "lable_path = 'datapath/labelpath'\n",
    "for file in os.listdir(lable_path): \n",
    "    with open(lable_path+file,\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        #print(lines)\n",
    "    with open(lable_path+file,\"w\") as f_w:\n",
    "        for line in lines:\n",
    "            aa = line.split(' ')[0]\n",
    "            print(aa)\n",
    "            if aa != '2' and aa != '0' and aa != '1' and aa != '3' and aa != '4':\n",
    "                continue\n",
    "            f_w.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete images with a target size greater than 0.5% of the entire image.\n",
    "from pathlib import Path\n",
    "\n",
    "def getGtAreaAndRatio(label_dir):\n",
    "    data_dict = {}\n",
    "    assert Path(label_dir).is_dir(), \"label_dir is not exist\"\n",
    "\n",
    "    txts = os.listdir(label_dir)  \n",
    "\n",
    "    for txt in txts:  \n",
    "         with open(os.path.join(label_dir, txt), 'r') as f:  \n",
    "            lines = f.readlines()\n",
    "         for line in lines:  \n",
    "               temp = line.split()  \n",
    "               coor_list = list(map(lambda x: x, temp[1:])) \n",
    "               area = float(coor_list[2]) * float(coor_list[3])  \n",
    "                  \n",
    "               ratio = round(float(coor_list[2]) / float(coor_list[3]), 2)  \n",
    "\n",
    "               if temp[0] not in data_dict:\n",
    "                  data_dict[temp[0]] = {}\n",
    "                  data_dict[temp[0]]['area'] = []\n",
    "                  data_dict[temp[0]]['ratio'] = []\n",
    "                  data_dict[temp[0]]['name'] = []\n",
    "\n",
    "               data_dict[temp[0]]['area'].append(area)\n",
    "               data_dict[temp[0]]['ratio'].append(ratio)\n",
    "               data_dict[temp[0]]['name'].append(txt)\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def getSMLGtNumByClass(data_dict, class_num):\n",
    "    s, m, l = 0, 0, 0\n",
    "    h = 1024\n",
    "    w = 1024\n",
    "    i = -1\n",
    "    for item in data_dict['{}'.format(class_num)]['area']:\n",
    "        i+=1\n",
    "        filenames = data_dict['{}'.format(class_num)]['name']\n",
    "        # print(filenames[i])\n",
    "        if item * h * w <= h * w * 0.005:\n",
    "            s += 1\n",
    "        elif item * h * w <= h * w * 0.010:\n",
    "            m += 1\n",
    "            print(labeldir+filenames[i], item)\n",
    "            if os.path.exists(labeldir+filenames[i]):\n",
    "                os.remove(labeldir+filenames[i])\n",
    "        else:\n",
    "            l += 1\n",
    "            print(labeldir+filenames[i], item)\n",
    "            if os.path.exists(labeldir+filenames[i]):\n",
    "                os.remove(labeldir+filenames[i])\n",
    "            \n",
    "    return s, m, l\n",
    "\n",
    "\n",
    "def getAllSMLGtNum(data_dict, isEachClass=False):\n",
    "    S, M, L = 0, 0, 0\n",
    "    \n",
    "    classDict = {'0': {'S': 0, 'M': 0, 'L': 0}, '1': {'S': 0, 'M': 0, 'L': 0}, '2': {'S': 0, 'M': 0, 'L': 0},\n",
    "                 '3': {'S': 0, 'M': 0, 'L': 0}, '4': {'S': 0, 'M': 0, 'L': 0}}\n",
    "\n",
    "    if isEachClass == False:\n",
    "        for i in range(1):\n",
    "            s, m, l = getSMLGtNumByClass(data_dict, i)\n",
    "            S += s\n",
    "            M += m\n",
    "            L += l\n",
    "        return [S, M, L]\n",
    "    else:\n",
    "        for i in range(5):\n",
    "            S = 0\n",
    "            M = 0\n",
    "            L = 0\n",
    "            total = 0\n",
    "            s, m, l = getSMLGtNumByClass(data_dict, i)\n",
    "            S += s\n",
    "            M += m\n",
    "            L += l\n",
    "            classDict[str(i)]['S'] = S\n",
    "            classDict[str(i)]['M'] = M\n",
    "            classDict[str(i)]['L'] = L\n",
    "            total += (S+M+L)\n",
    "            print(\"total: \", total)\n",
    "        return classDict\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    labeldir = 'datapath'\n",
    "    data_dict = getGtAreaAndRatio(labeldir)\n",
    "    isEachClass = True\n",
    "    SML = getAllSMLGtNum(data_dict, isEachClass)\n",
    "    print(SML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    data = \"data.yaml\"\n",
    "\n",
    "    model = YOLO('scw-yolo.yaml')\n",
    "    model.train(data=data, epochs=200, imgsz=640, batch=8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
